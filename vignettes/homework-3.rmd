---
title: "Homework-3"
author: "Wenfeng Zhang"
date: "`r Sys.Date()`"
output:
  html_document:
    self_contained: yes
    toc: true
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{The ridge regression vignette}
-->

## Problem 1 (117.7)
```{r}
set.seed(3154)
x <- rnorm(1000, 0, 1)
x.new <- sort(rnorm(50, 0, 1))

kernel_epan <- function(x) {
ran <- as.numeric(abs(x) <= 1)
val <- (3/4) * ( 1 - x^2 ) * ran
return(val)
}

kernel_epan(x)
i = 1
h = 1
kern_density <- function(x, h, x.new){
  dst_est <- numeric()
  for (i in 1:length(x.new)){
    dst_est[i] <- mean(kernel_epan((x.new[i]-x)/h))/h
  }
  dst_est
}
h = c(0.1, 0.5, 1, 2, 3)
for (i in h){
  plot(x.new, kern_density(x,i,x.new), ylab = "Density", main = "Kernal density estimation", type = "l")  
}

```


## Problem 2 (200.3)
By definition of convex function, for $t \in [0, 1]$
$$
\begin{aligned}
f(t x + (1 - t)y) &\leq t f(x) + (1 - t)f(y)\\
g(t x + (1 - t)y) &\leq t g(x) + (1 - t)g(y)\\
\end{aligned}
$$
Then
$$
\begin{aligned}
h(t x + (1 - t)y) &= f(t x + (1 - t)y) + g(t x + (1 - t)y)\\
&\leq t f(x) + (1 - t)f(y) + t g(x) + (1 - t)g(y)\\
&=t (f(x) + g(x)) + (1 - t)(f(y) + g(y))\\
&=t h(x) + (1 - t) h(y)
\end{aligned}
$$
Therefore, $h = f + g$ is convex.

## Problem 3 (200.4)
For $t \in [0, 1]$
$$
\begin{aligned}
f(x) &= |x|\\
f(tx+(1-t)y)&=|tx+(1-t)y|\\
&\leq |tx| + |(1-t)y|\\
&=f(tx)+f((1-t)y)\\
&=tf(x)+(1-t)f(y)
\end{aligned}
$$
Thus, $f(x)$ is convex.  
By Problem 3 (200.3), $l_1\ norm= \sum_{i = 1}|v_i|$ is convex

## Problem 4 (200.5)

$l_2\ norm$
$$
\begin{aligned}
f(x) &= x^2\\
f(tx+(1-t)y) &=t^2x^2 + (1-t)^2y^2+2t(1-t)xy \\
tf(x)+(1-t)f(y)&=tx^2+(1-t)y\\
f(tx+(1-t)y)-[tf(x)+(1-t)f(y)]&=t(t-1)x^2+t(t-1)y^2+2t(1-t)xy\\
&=t(1-t)(-x^2-y^2+2xy)\\
&=t(t-1)(x-y)^2\\
&\leq0\ \ since\ 0\leq t \leq1\\
f(tx+(1-t)y) &\leq tf(x)+(1-t)f(y)
\end{aligned}
$$

Therefore, $f(x) = x^2$ is convex. 
Objective function of elastic net
$$\frac{1}{2n}||y-Xb||^2_2+\lambda[(1-\alpha)\frac{1}{2}||b||^2_2+\alpha||b||_1]$$
It's a sum of $l_2\ norm$ and $l_1\ norm$, by 3 and 4, it's convex

## Problem 5 (200.6)

```{r}
library(glmnet)
# KKT check function
check_kkt <- function(y, X, b, lambda) {
  resids <- y - X %*% b 
  s <- apply(X, 2, function(xj) crossprod(xj, resids)) / lambda / nrow(X)
  (b == 0) & (abs(s) >= 1)
}

# use iris as dataset
x <- scale(model.matrix(Sepal.Length ~. -1, iris))
y <- iris[,1]

# implement lasso (set alpha to 0)
lasso_reg_with_screening <- function(x, y){
  m1 <- cv.glmnet(x,y,alpha=1)
  lambda <- m1$lambda.1se
  b <- m1$glmnet.fit$beta[, m1$lambda == lambda]
  print(b)
  check_kkt(y, x, b, lambda)
}

lasso_reg_with_screening(x, y)
```

The KTT check of all coefficients are FALSE, indicating there is no KTT violation in above case. 
